{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"100Bgtbbon-pB5A32BbBvP675I3W1RkkZ","authorship_tag":"ABX9TyMXAIRlJNegvxvidt8e0zAh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oI6l7RqKFhLj","executionInfo":{"status":"ok","timestamp":1750769338690,"user_tz":-330,"elapsed":15658,"user":{"displayName":"ADHIN AJAY","userId":"06810354814766625457"}},"outputId":"14c6447d-2939-41a0-d8bc-178b87854669"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install ultralytics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b8Kf9PCUFsoQ","executionInfo":{"status":"ok","timestamp":1750781490545,"user_tz":-330,"elapsed":91829,"user":{"displayName":"ADHIN AJAY","userId":"06810354814766625457"}},"outputId":"63047c29-2cb4-45b5-cc2a-26315c75c9d4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.3.159-py3-none-any.whl.metadata (37 kB)\n","Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.4)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.6.15)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n","Downloading ultralytics-8.3.159-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m97.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n","Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.159 ultralytics-thop-2.0.14\n"]}]},{"cell_type":"code","source":["pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"LkFZjNKJzYkr","executionInfo":{"status":"ok","timestamp":1750781524849,"user_tz":-330,"elapsed":27,"user":{"displayName":"ADHIN AJAY","userId":"06810354814766625457"}},"outputId":"d492544f-608c-4b5b-b7ae-e54171aae79a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/NITC/Quantization New/YOLOv8n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["cd '/content/drive/MyDrive/NITC/Quantization New/YOLOv8n'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-eN28kcfzbSU","executionInfo":{"status":"ok","timestamp":1750781490580,"user_tz":-330,"elapsed":16,"user":{"displayName":"ADHIN AJAY","userId":"06810354814766625457"}},"outputId":"276cba58-bedc-4790-8a1f-04770652e4d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/NITC/Quantization New/YOLOv8n\n"]}]},{"cell_type":"code","source":["from ultralytics import YOLO\n","\n","model = YOLO('bestn.pt')  # Replace with your model file\n","metrics = model.val(data='/content/drive/MyDrive/NITC/yolov8_newdata/dataset.yaml')  # Replace with your data.yaml path"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q4mMpCJezt3X","executionInfo":{"status":"ok","timestamp":1750699574822,"user_tz":-330,"elapsed":36271,"user":{"displayName":"ADHIN AJAY","userId":"06810354814766625457"}},"outputId":"2150ae49-ba21-4860-8d15-0992fad181c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.158 🚀 Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n","YOLOv8n summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 755k/755k [00:00<00:00, 15.2MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 1.4±1.9 ms, read: 1.5±0.3 MB/s, size: 384.6 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/NITC/yolov8_newdata/datanew/labels/val.cache... 30 images, 0 backgrounds, 0 corrupt: 100%|██████████| 30/30 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:20<00:00, 10.49s/it]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         30        258      0.787      0.903      0.889      0.626\n","Speed: 10.2ms preprocess, 235.2ms inference, 0.0ms loss, 2.0ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val\u001b[0m\n"]}]},{"cell_type":"code","source":["import time\n","from ultralytics import YOLO\n","\n","# ✅ Load the trained model (you must give the .pt file here)\n","model = YOLO('bestn.pt')\n","\n","start_time=time.time()\n","\n","# ✅ Run prediction on the test images\n","results = model.predict(\n","    source='/content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val',  # path to test images\n","    save=True,  # saves output images with boxes\n","    conf=0.25   # confidence threshold (adjustable)\n",")\n","end_time=time.time()\n","print(end_time-start_time)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PrcX7pL4Dgi-","executionInfo":{"status":"ok","timestamp":1750770541680,"user_tz":-330,"elapsed":9258,"user":{"displayName":"ADHIN AJAY","userId":"06810354814766625457"}},"outputId":"3d7796ab-2e61-45ee-ad2c-a3e9284d5312"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","image 1/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142513.JPG: 480x640 7 mcells, 417.8ms\n","image 2/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142514.JPG: 480x640 12 mcells, 145.6ms\n","image 3/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142516.JPG: 480x640 11 mcells, 166.4ms\n","image 4/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142517.JPG: 480x640 7 mcells, 152.7ms\n","image 5/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142522.JPG: 480x640 6 mcells, 146.0ms\n","image 6/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142526.JPG: 480x640 4 mcells, 144.0ms\n","image 7/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142527.JPG: 480x640 1 mcell, 146.1ms\n","image 8/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142539.JPG: 480x640 3 mcells, 162.1ms\n","image 9/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142540.JPG: 480x640 8 mcells, 148.9ms\n","image 10/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142542.JPG: 480x640 36 mcells, 157.5ms\n","image 11/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142550.JPG: 480x640 19 mcells, 145.9ms\n","image 12/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142576.JPG: 480x640 20 mcells, 259.1ms\n","image 13/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142578.JPG: 480x640 32 mcells, 234.7ms\n","image 14/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142579.JPG: 480x640 11 mcells, 226.7ms\n","image 15/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142586.JPG: 480x640 15 mcells, 235.9ms\n","image 16/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153279.JPG: 480x640 27 mcells, 239.3ms\n","image 17/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153282.JPG: 480x640 24 mcells, 226.6ms\n","image 18/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153301.JPG: 480x640 2 mcells, 229.7ms\n","image 19/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153303.JPG: 480x640 5 mcells, 246.4ms\n","image 20/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153310.JPG: 480x640 4 mcells, 225.7ms\n","image 21/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153315.JPG: 480x640 6 mcells, 223.1ms\n","image 22/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153317.JPG: 480x640 3 mcells, 253.8ms\n","image 23/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153324.JPG: 480x640 4 mcells, 248.5ms\n","image 24/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153336.JPG: 480x640 3 mcells, 234.4ms\n","image 25/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153344.JPG: 480x640 3 mcells, 185.3ms\n","image 26/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153397.JPG: 480x640 29 mcells, 148.8ms\n","image 27/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153400.JPG: 480x640 7 mcells, 161.4ms\n","image 28/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153407.JPG: 480x640 10 mcells, 148.4ms\n","image 29/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153408.JPG: 480x640 20 mcells, 166.8ms\n","image 30/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153416.JPG: 480x640 7 mcells, 154.3ms\n","Speed: 4.6ms preprocess, 199.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n","8.133762836456299\n"]}]},{"cell_type":"markdown","source":["Conveting .pt file onnx file"],"metadata":{"id":"qXCt8ECr1hMZ"}},{"cell_type":"code","source":["from ultralytics import YOLO\n","\n","model = YOLO('bestn.pt')\n","model.export(format = 'onnx') # exports the model in '.onnx' format"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":383},"id":"5BTgWhAV0g9b","executionInfo":{"status":"ok","timestamp":1750699773994,"user_tz":-330,"elapsed":7402,"user":{"displayName":"ADHIN AJAY","userId":"06810354814766625457"}},"outputId":"f33c4240-218d-42e1-a47b-05ed914f565d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.158 🚀 Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n","💡 ProTip: Export to OpenVINO format for best performance on Intel CPUs. Learn more at https://docs.ultralytics.com/integrations/openvino/\n","YOLOv8n summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n","\n","\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'bestn.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (6.0 MB)\n","\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx>=1.12.0,<1.18.0', 'onnxslim>=0.1.56', 'onnxruntime'] not found, attempting AutoUpdate...\n","\n","\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 3.8s\n","WARNING ⚠️ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n","\n","\n","\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n","\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.58...\n","\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 6.5s, saved as 'bestn.onnx' (11.7 MB)\n","\n","Export complete (7.2s)\n","Results saved to \u001b[1m/content/drive/MyDrive/NITC/Quantization New/YOLOv8n\u001b[0m\n","Predict:         yolo predict task=detect model=bestn.onnx imgsz=640  \n","Validate:        yolo val task=detect model=bestn.onnx imgsz=640 data=/workspace/yolo_v8/datanew/dataset.yaml  \n","Visualize:       https://netron.app\n"]},{"output_type":"execute_result","data":{"text/plain":["'bestn.onnx'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["!pip install onnxruntime onnx"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CSGmVRxO2Dz-","executionInfo":{"status":"ok","timestamp":1750699892266,"user_tz":-330,"elapsed":5854,"user":{"displayName":"ADHIN AJAY","userId":"06810354814766625457"}},"outputId":"56c51ed0-3fa7-4b4b-a1e5-2776efdc240f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: onnxruntime in /usr/local/lib/python3.11/dist-packages (1.22.0)\n","Requirement already satisfied: onnx in /usr/local/lib/python3.11/dist-packages (1.17.0)\n","Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (15.0.1)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n","Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (2.0.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (5.29.5)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.14.0)\n","Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime) (10.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n"]}]},{"cell_type":"markdown","source":["Preprocessing the model"],"metadata":{"id":"71LprkA12XA1"}},{"cell_type":"code","source":["!python -m onnxruntime.quantization.preprocess --input bestn.onnx --output preprocessed.onnx"],"metadata":{"id":"LK_igRtn2QKO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Coverting FP32 to INT8 through Dynamic Quantization"],"metadata":{"id":"1fKt_SP02b2Q"}},{"cell_type":"code","source":["from onnxruntime.quantization import quantize_dynamic, QuantType\n","\n","model_fp32 = 'preprocessed.onnx'\n","model_int8 = 'dynamic_quantized.onnx'\n","\n","# Quantize\n","quantize_dynamic(model_fp32, model_int8, weight_type=QuantType.QUInt8)"],"metadata":{"id":"EHv72fC52WRg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Coverting FP32 to INT8 through Static Quantization"],"metadata":{"id":"GkgsIzJt2in-"}},{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","from onnxruntime.quantization import CalibrationDataReader\n","\n","# Class for Calibration Data reading\n","class ImageCalibrationDataReader(CalibrationDataReader):\n","    def __init__(self, image_paths):\n","        self.image_paths = image_paths\n","        self.idx = 0\n","        self.input_name = \"images\"\n","\n","    def preprocess(self, frame_path):\n","        frame = cv2.imread(frame_path)\n","        if frame is None:\n","            raise ValueError(f\"Could not read image: {frame_path}\")\n","        X = cv2.resize(frame, (640, 640))\n","        image_data = X.astype(np.float32) / 255.0  # Normalize to [0, 1]\n","        image_data = np.transpose(image_data, (2, 0, 1))  # (H, W, C) -> (C, H, W)\n","        image_data = np.expand_dims(image_data, axis=0)  # Add batch dimension\n","        return image_data\n","\n","    def get_next(self):\n","        if self.idx >= len(self.image_paths):\n","            return None\n","        image_path = self.image_paths[self.idx]\n","        input_data = self.preprocess(image_path)\n","        self.idx += 1\n","        return {self.input_name: input_data}\n","\n","# Collect all image file paths from the \"samples\" folder\n","image_folder = \"samples\"\n","calibration_image_paths = [\n","    os.path.join(image_folder, fname)\n","    for fname in os.listdir(image_folder)\n","    if fname.lower().endswith(('.jpg', '.jpeg', '.png'))\n","]\n","\n","# Create the data reader instance\n","calibration_data_reader = ImageCalibrationDataReader(calibration_image_paths)\n"],"metadata":{"id":"WAiDZ1MO2knh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","from onnxruntime.quantization import quantize_static, QuantType, QuantFormat\n","\n","# Use the calibration_data_reader with quantize_static\n","quantize_static('preprocessed.onnx', \"static_quantized.onnx\",\n","                weight_type=QuantType.QInt8,\n","                activation_type=QuantType.QUInt8,\n","                calibration_data_reader=calibration_data_reader,\n","                quant_format=QuantFormat.QDQ,\n","                nodes_to_exclude=['/model.22/Concat_3', '/model.22/Split', '/model.22/Sigmoid'\n","                                 '/model.22/dfl/Reshape', '/model.22/dfl/Transpose', '/model.22/dfl/Softmax',\n","                                 '/model.22/dfl/conv/Conv', '/model.22/dfl/Reshape_1', '/model.22/Slice_1',\n","                                 '/model.22/Slice', '/model.22/Add_1', '/model.22/Sub', '/model.22/Div_1',\n","                                  '/model.22/Concat_4', '/model.22/Mul_2', '/model.22/Concat_5'],\n","                per_channel=False,\n","                reduce_range=True,)"],"metadata":{"id":"clZHrbVo3fgV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Validation on Static Quantized Model"],"metadata":{"id":"kgUujh7b35rd"}},{"cell_type":"code","source":["from ultralytics import YOLO\n","\n","model = YOLO('static_quantized.onnx')  # Replace with your model file\n","metrics = model.val(data='/content/drive/MyDrive/NITC/yolov8_newdata/dataset.yaml')  # Replace with your data.yaml path"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n-T-WthO35Rx","executionInfo":{"status":"ok","timestamp":1750700431575,"user_tz":-330,"elapsed":9975,"user":{"displayName":"ADHIN AJAY","userId":"06810354814766625457"}},"outputId":"ae318aed-b2b3-4c43-daa2-62d56337080b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING ⚠️ Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n","Ultralytics 8.3.158 🚀 Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n","Loading static_quantized.onnx for ONNX Runtime inference...\n","Using ONNX Runtime CPUExecutionProvider\n","Setting batch=1 input of shape (1, 3, 640, 640)\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 2.3±3.3 ms, read: 82.2±43.1 MB/s, size: 374.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/NITC/yolov8_newdata/datanew/labels/val.cache... 30 images, 0 backgrounds, 0 corrupt: 100%|██████████| 30/30 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:06<00:00,  4.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         30        258      0.814      0.847      0.885       0.59\n","Speed: 2.8ms preprocess, 171.3ms inference, 0.0ms loss, 1.6ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val2\u001b[0m\n"]}]},{"cell_type":"code","source":["import time\n","from ultralytics import YOLO\n","\n","# ✅ Load the trained model (you must give the .pt file here)\n","model = YOLO('static_quantized.onnx')\n","\n","start_time=time.time()\n","\n","# ✅ Run prediction on the test images\n","results = model.predict(\n","    source='/content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val',  # path to test images\n","    save=True,  # saves output images with boxes\n","    conf=0.25   # confidence threshold (adjustable)\n",")\n","end_time=time.time()\n","print(end_time-start_time)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6nwp7gt8DONA","executionInfo":{"status":"ok","timestamp":1750770466202,"user_tz":-330,"elapsed":6582,"user":{"displayName":"ADHIN AJAY","userId":"06810354814766625457"}},"outputId":"e00ce3bf-3b2f-4d2b-9924-1b8dfc391186"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING ⚠️ Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n","Loading static_quantized.onnx for ONNX Runtime inference...\n","Using ONNX Runtime CPUExecutionProvider\n","\n","image 1/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142513.JPG: 640x640 7 mcells, 196.5ms\n","image 2/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142514.JPG: 640x640 10 mcells, 193.4ms\n","image 3/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142516.JPG: 640x640 11 mcells, 189.2ms\n","image 4/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142517.JPG: 640x640 8 mcells, 201.5ms\n","image 5/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142522.JPG: 640x640 6 mcells, 192.3ms\n","image 6/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142526.JPG: 640x640 4 mcells, 194.2ms\n","image 7/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142527.JPG: 640x640 1 mcell, 173.1ms\n","image 8/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142539.JPG: 640x640 3 mcells, 111.1ms\n","image 9/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142540.JPG: 640x640 7 mcells, 118.0ms\n","image 10/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142542.JPG: 640x640 34 mcells, 111.3ms\n","image 11/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142550.JPG: 640x640 20 mcells, 111.2ms\n","image 12/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142576.JPG: 640x640 18 mcells, 114.9ms\n","image 13/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142578.JPG: 640x640 27 mcells, 112.8ms\n","image 14/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142579.JPG: 640x640 10 mcells, 134.1ms\n","image 15/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142586.JPG: 640x640 16 mcells, 112.4ms\n","image 16/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153279.JPG: 640x640 29 mcells, 111.3ms\n","image 17/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153282.JPG: 640x640 24 mcells, 112.6ms\n","image 18/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153301.JPG: 640x640 3 mcells, 117.9ms\n","image 19/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153303.JPG: 640x640 4 mcells, 129.9ms\n","image 20/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153310.JPG: 640x640 4 mcells, 112.1ms\n","image 21/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153315.JPG: 640x640 4 mcells, 111.2ms\n","image 22/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153317.JPG: 640x640 3 mcells, 114.1ms\n","image 23/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153324.JPG: 640x640 6 mcells, 114.3ms\n","image 24/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153336.JPG: 640x640 2 mcells, 113.4ms\n","image 25/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153344.JPG: 640x640 3 mcells, 132.0ms\n","image 26/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153397.JPG: 640x640 29 mcells, 114.6ms\n","image 27/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153400.JPG: 640x640 7 mcells, 116.3ms\n","image 28/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153407.JPG: 640x640 10 mcells, 113.9ms\n","image 29/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153408.JPG: 640x640 18 mcells, 118.6ms\n","image 30/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153416.JPG: 640x640 7 mcells, 129.5ms\n","Speed: 5.1ms preprocess, 134.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns/detect/predict2\u001b[0m\n","6.558886289596558\n"]}]},{"cell_type":"markdown","source":["Detection Dynamic"],"metadata":{"id":"uMzwtmG8_BYS"}},{"cell_type":"code","source":["from ultralytics import YOLO\n","\n","model = YOLO('dynamic_quantized.onnx')  # Replace with your model file\n","metrics = model.val(data='/content/drive/MyDrive/NITC/yolov8_newdata/dataset.yaml')  # Replace with your data.yaml path"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DKsOKBhR_DaV","executionInfo":{"status":"ok","timestamp":1750770287577,"user_tz":-330,"elapsed":12379,"user":{"displayName":"ADHIN AJAY","userId":"06810354814766625457"}},"outputId":"9563c6cd-e122-4232-ac73-6c98271178c7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING ⚠️ Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n","Ultralytics 8.3.159 🚀 Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n","Loading dynamic_quantized.onnx for ONNX Runtime inference...\n","Using ONNX Runtime CPUExecutionProvider\n","Setting batch=1 input of shape (1, 3, 640, 640)\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.6±0.3 ms, read: 70.0±22.2 MB/s, size: 330.8 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/NITC/yolov8_newdata/datanew/labels/val.cache... 30 images, 0 backgrounds, 0 corrupt: 100%|██████████| 30/30 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:08<00:00,  3.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         30        258      0.813      0.875      0.892      0.631\n","Speed: 1.7ms preprocess, 251.3ms inference, 0.0ms loss, 1.6ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val4\u001b[0m\n"]}]},{"cell_type":"code","source":["import time\n","from ultralytics import YOLO\n","\n","# ✅ Load the trained model (you must give the .pt file here)\n","model = YOLO('dynamic_quantized.onnx')\n","\n","start_time=time.time()\n","\n","# ✅ Run prediction on the test images\n","results = model.predict(\n","    source='/content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val',  # path to test images\n","    save=True,  # saves output images with boxes\n","    conf=0.25   # confidence threshold (adjustable)\n",")\n","end_time=time.time()\n","print(end_time-start_time)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E91BQ98KCbLt","executionInfo":{"status":"ok","timestamp":1750770482680,"user_tz":-330,"elapsed":10211,"user":{"displayName":"ADHIN AJAY","userId":"06810354814766625457"}},"outputId":"a3ca58c9-500e-40f8-851c-2527abdf09bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING ⚠️ Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n","Loading dynamic_quantized.onnx for ONNX Runtime inference...\n","Using ONNX Runtime CPUExecutionProvider\n","\n","image 1/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142513.JPG: 640x640 8 mcells, 308.8ms\n","image 2/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142514.JPG: 640x640 10 mcells, 305.7ms\n","image 3/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142516.JPG: 640x640 12 mcells, 313.3ms\n","image 4/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142517.JPG: 640x640 8 mcells, 313.6ms\n","image 5/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142522.JPG: 640x640 6 mcells, 322.9ms\n","image 6/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142526.JPG: 640x640 4 mcells, 316.8ms\n","image 7/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142527.JPG: 640x640 1 mcell, 324.4ms\n","image 8/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142539.JPG: 640x640 3 mcells, 232.1ms\n","image 9/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142540.JPG: 640x640 8 mcells, 196.4ms\n","image 10/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142542.JPG: 640x640 34 mcells, 197.0ms\n","image 11/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142550.JPG: 640x640 20 mcells, 191.1ms\n","image 12/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142576.JPG: 640x640 21 mcells, 207.3ms\n","image 13/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142578.JPG: 640x640 29 mcells, 192.1ms\n","image 14/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142579.JPG: 640x640 10 mcells, 191.4ms\n","image 15/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9142586.JPG: 640x640 15 mcells, 191.7ms\n","image 16/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153279.JPG: 640x640 29 mcells, 211.9ms\n","image 17/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153282.JPG: 640x640 24 mcells, 192.2ms\n","image 18/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153301.JPG: 640x640 2 mcells, 194.8ms\n","image 19/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153303.JPG: 640x640 4 mcells, 191.9ms\n","image 20/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153310.JPG: 640x640 4 mcells, 203.8ms\n","image 21/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153315.JPG: 640x640 4 mcells, 191.1ms\n","image 22/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153317.JPG: 640x640 3 mcells, 194.8ms\n","image 23/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153324.JPG: 640x640 5 mcells, 195.2ms\n","image 24/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153336.JPG: 640x640 2 mcells, 241.2ms\n","image 25/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153344.JPG: 640x640 3 mcells, 368.5ms\n","image 26/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153397.JPG: 640x640 30 mcells, 395.0ms\n","image 27/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153400.JPG: 640x640 7 mcells, 357.2ms\n","image 28/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153407.JPG: 640x640 9 mcells, 359.7ms\n","image 29/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153408.JPG: 640x640 18 mcells, 432.6ms\n","image 30/30 /content/drive/MyDrive/NITC/yolov8_newdata/datanew/images/val/P9153416.JPG: 640x640 7 mcells, 346.2ms\n","Speed: 6.3ms preprocess, 262.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns/detect/predict3\u001b[0m\n","10.215168952941895\n"]}]},{"cell_type":"markdown","source":["Detection using another image"],"metadata":{"id":"rIc93YwhuMtE"}},{"cell_type":"code","source":["import time\n","from ultralytics import YOLO\n","\n","# ✅ Load the trained model (you must give the .pt file here)\n","model = YOLO('static_quantized.onnx')\n","\n","start_time=time.time()\n","\n","# ✅ Run prediction on the test images\n","results = model.predict(\n","    source='/content/drive/MyDrive/NITC/istockphoto.jpg',  # path to test images\n","    save=True,  # saves output images with boxes\n","    conf=0.25   # confidence threshold (adjustable)\n",")\n","end_time=time.time()\n","print(\"Inference Time:\",end_time-start_time)\n"],"metadata":{"id":"iNkNXUej_DIe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750781638490,"user_tz":-330,"elapsed":274,"user":{"displayName":"ADHIN AJAY","userId":"06810354814766625457"}},"outputId":"37381e0d-2a72-4799-e68a-7dcc102b8483"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING ⚠️ Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n","Loading static_quantized.onnx for ONNX Runtime inference...\n","Using ONNX Runtime CPUExecutionProvider\n","\n","image 1/1 /content/drive/MyDrive/NITC/istockphoto.jpg: 640x640 7 mcells, 111.6ms\n","Speed: 5.2ms preprocess, 111.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns/detect/predict6\u001b[0m\n","Inference Time: 0.2656097412109375\n"]}]}]}